{
    "contents" : "\nlibrary(shiny)\nlibrary(tm)\n\nload('unigramdf.RData')\nload('bipred.RData')\nload('tripred.RData')\nload('quadpred.RData')\n\nload('dict.RData')\n\n\n# function to clean EN text\ncleanEnText <- function (txt, bRemoveStopWords) {\n  txt <- tolower(txt)\n  #cat(sprintf(\"before: %s\\n\", txt), file=stderr())\n  \n  txt <- gsub(\"'m \", \" am \", txt)\n  txt <- gsub(\"'s \", \" \", txt)\n  txt <- gsub(\"'ll \", \" will \", txt)\n  txt <- gsub(\"'ve \", \" have \", txt)\n  txt <- gsub(\"'d \", \" would \", txt)\n  txt <- gsub(\"n't \", \" not \", txt)\n  \n  txt <- gsub(\" r \", \" are \", txt)\n  txt <- gsub(\" u \", \" you \", txt)\n  txt <- gsub(\" n \", \" and \", txt)\n  \n  txt <- gsub(\" wld \", \" would \", txt)\n  txt <- gsub(\" cld \", \" could \", txt)\n  txt <- gsub(\" thru \", \" through \", txt)\n  \n  txt <- gsub(\" d; \", \" \", txt)\n  txt <- gsub(\" p; \", \" \", txt)\n  \n  \n  # cleaning the data:\n  # 1. convert to lower case --- expected to be done\n  #txt <- tolower(txt)\n  # 2. remove extra whitespace\n  txt <- stripWhitespace(txt)\n  # 3. remove bad words\n  if(bRemoveStopWords) txt <- removeWords(txt, stopwords('english'))\n  # 4. remove punctuation\n  txt <- removePunctuation(txt)\n  # 5. remove numbers\n  txt <- removeNumbers(txt)\n  \n  # stem documents\n  #txt <- stemDocument(txt)\n\n  #cat(sprintf(\"after: %s\\n\", txt), file=stderr())\n  return( txt )\n}\n\ngetTopNGram <- function( ngram.df , term, n_top ) {\n  ret.df <- data.frame(pred=character(0), count= integer(0))\n  \n  res.df <- ngram.df[which(term==ngram.df$pre),]\n  n <- nrow(res.df)\n  #cat(as.character(res.df[1:5,]), file=stderr())\n  #cat(sprintf(\"\\nlooking for:%s , here found=%d\\n\", term, n), file=stderr())\n  \n  if( n > 0 ) {\n    topTerms <- res.df[order(res.df$count, decreasing=TRUE), c('pred', 'count')]\n  \n    if(0 != n_top)  n <- ifelse(n_top > n, n, n_top)\n  \n    topTerms$pred  <- as.character(topTerms$pred)\n    topTerms$count <- as.integer(topTerms$count)\n    \n    ret.df <- topTerms[1:n,]\n  }\n  \n  return( ret.df )\n}\n\n\npredictWordNgram <- function( sentence, grep_pred ) {\n  res1.ngram <- data.frame(pred=character(0), count= integer(0))\n  res2.ngram <- data.frame(pred=character(0), count= integer(0))\n  top.ngram  <- data.frame(pred=character(0), count= integer(0))\n  \n  en_txt <- ''\n  \n  en_txt <- cleanEnText(sentence, TRUE)\n  res1.ngram <- predictor(en_txt, grep_pred)\n  iRes1 <- nrow(res1.ngram)\n  \n  en_txt <- cleanEnText(sentence, FALSE)\n  res2.ngram <- predictor(en_txt, grep_pred)  \n  iRes2 <- nrow(res2.ngram)\n  \n  if( iRes1 > 0 )  top.ngram <- res1.ngram\n  if( iRes2 > 0 )  top.ngram <- rbind(top.ngram, res2.ngram)\n    \n  if( (iRes1>0) && (iRes2>0) ) top.ngram <- aggregate(count ~ pred, top.ngram, FUN=sum)\n  if( (iRes1 + iRes2) > 0 ) top.ngram <- top.ngram[order(top.ngram$count, decreasing=TRUE), ]\n  \n  #cat(sprintf(\"iRes1=%d, iRes2=%d\\n\", iRes1, iRes2), file=stderr())\n  return( top.ngram )\n}\n\npredictor <- function( en_txt, grep_pred ) {\n  top.ngram <- data.frame(pred=character(0), count= integer(0))\n  \n  iBiChoice   <- 0\n  iTriChoice  <- 0\n  iQuadChoice <- 0\n  \n  no_ngram     <- 0\n  no_trigram   <- 0\n  no_quadigram <- 0\n  \n    \n  words <- unlist(strsplit(en_txt, split=\" \"))\n  len   <- length(words)\n  \n  \n  top.trigram <- getTopNGram(triterm.pred, paste(words[len-1],words[len]), 0)\n  if( '' != grep_pred ) {\n    rows <- grep(grep_pred, top.trigram$pred)\n    top.trigram <- top.trigram[rows,]\n  }\n  iTriChoice <- nrow(top.trigram[complete.cases(top.trigram),])\n  #cat(sprintf(\"actually looking: %s [%s], found=%d\\n\", paste(words[len-1],words[len]), grep_pred, iTriChoice), file=stderr())\n  \n  \n  if( iTriChoice > 0) { #possible to have quadigram\n    top.quadigram <- getTopNGram(quaditerm.pred, paste(words[len-2],paste(words[len-1],words[len])), 0)\n    if( '' != grep_pred ) {\n      rows <- grep(grep_pred, top.quadigram$pred)\n      top.quadigram <- top.quadigram[rows,]\n    }\n    iQuadChoice <- nrow(top.quadigram[complete.cases(top.quadigram),])\n  }\n  \n  if( 0 != iQuadChoice ) {\n    no_quadigram <- ifelse( (iQuadChoice >= 2), 2, 1 )\n    top.ngram <- top.quadigram[order(top.quadigram$count, decreasing=TRUE), ][1:no_quadigram,]\n    no_ngram <- no_quadigram\n  }\n  \n  if( 0 != iTriChoice ) {\n    no_trigram <- ifelse( ((iTriChoice+no_quadigram) >= 3),\n                          ifelse( (iTriChoice >= 3), 3, iTriChoice ),\n                          iTriChoice )\n    top.ngram <- rbind(top.ngram, top.trigram[order(top.trigram$count, decreasing=TRUE), ][1:no_trigram,])\n    \n    top.ngram <- aggregate(count~pred, top.ngram, FUN=sum)\n    no_ngram  <- nrow(top.ngram[complete.cases(top.ngram),])\n  }\n  \n  \n  if( no_ngram < 3 ) { #still need bigram\n    top.bigram <- getTopNGram(biterm.pred, words[len], 0)\n    if( '' != grep_pred ) {\n      rows <- grep(grep_pred, top.bigram$pred)\n      top.bigram <- top.bigram[rows,]\n    }\n    iBiChoice <- nrow(top.bigram[complete.cases(top.bigram),])\n    \n    if( iBiChoice > 0) {\n      no_bigram <- ifelse( ((iBiChoice+no_ngram) >= 3), (3-no_ngram), iBiChoice ) #limit bigram\n      top.ngram <- rbind(top.ngram, top.bigram[order(top.bigram$count, decreasing=TRUE), ][1:no_bigram,])\n      \n      top.ngram <- aggregate(count~pred, top.ngram, FUN=sum)\n    }\n  }\n\n  #cat(sprintf(\"iQuadChoice=%d, iTriChoice=%d, iBiChoice=%d\\n\", iQuadChoice, iTriChoice, iBiChoice), file=stderr())\n  return( top.ngram )\n}\n\n\n\n\npredictWord <- function( txt ) {\n  s <- '<h4>...</h4>'\n  \n  if(' ' == substr(txt, nchar(txt), nchar(txt))) {\n    word.predict <- predictWordNgram(txt, '')\n    \n    if( nrow(word.predict[complete.cases(word.predict),]) > 0 ) {\n      s <- sprintf(\"<h3><strong>[1] %s</strong></h3>  <em>[2] %s , [3] %s</em>\",    \n                  word.predict[1,]$pred,word.predict[2,]$pred,word.predict[3,]$pred)\n    }\n  }\n  else if( nchar(txt) > 0 ) {\n    words <- unlist(strsplit(txt, split=\" \"))\n    len   <- length(words)\n    \n    word.predict <- predictWordNgram(paste(paste(words[1:len-1], collapse=\" \"), \"\"), sprintf(\"^%s\",words[len]))\n    no_res <- nrow(word.predict[complete.cases(word.predict),])\n    \n    if( 0 == no_res ) { #no result\n       #check Unigram and Dictionary(??)\n      rows   <- grep(sprintf(\"^%s\", words[len]), unigram.df$term)\n      no_res <- length(rows)\n    \n      if( 0 == no_res ) { #no result from ngram, check Dictionary\n        rows <- grep(sprintf(\"^%s\", words[len]), dict)\n        no_res <- length(rows)\n        \n        if( no_res > 0 ) { #result from dictionary\n          word.predict <- dict[rows]\n          \n          s <- sprintf(\"<h3><strong>[1] %s</strong></h3>  <em>[2] %s , [3] %s</em>\",    \n                       word.predict[1],word.predict[2],word.predict[3])\n        }\n        #else, no result from everywhere!\n      }\n      else { #result from unigram\n        word.predict <- unigram.df[rows,]\n        word.predict <- word.predict[order(word.predict$count, decreasing=TRUE), ]\n\n        s <- sprintf(\"<h3><strong>[1] %s</strong></h3>  <em>[2] %s , [3] %s</em>\",    \n                     word.predict[1,]$term,word.predict[2,]$term,word.predict[3,]$term)\n      }\n    }\n    else { #result from ngram\n      s <- sprintf(\"<h3><strong>[1] %s</strong></h3>  <em>[2] %s , [3] %s</em>\",    \n                   word.predict[1,]$pred,word.predict[2,]$pred,word.predict[3,]$pred)\n    }\n  }\n  \n  as.character(s)\n}",
    "created" : 1429934380946.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2451673565",
    "id" : "F7B47838",
    "lastKnownWriteTime" : 1430034629,
    "path" : "/media/Data/EDU/coursera/ida_datasci/[10] Data Science Capstone/source/wordpredict/global.R",
    "project_path" : "global.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}