{
    "contents" : "\nlibrary(shiny)\nlibrary(tm)\n\nload('unigram-700.RData')\nload('bipred.RData')\nload('tripred.RData')\nload('quadpred.RData')\n\n\n# function to clean EN text\ncleanEnText <- function (txt) {\n  txt <- tolower(txt)\n  \n  txt <- gsub(\"'m \", \" am \", txt)\n  txt <- gsub(\"'s \", \" \", txt)\n  txt <- gsub(\"'ll \", \" will \", txt)\n  txt <- gsub(\"'ve \", \" have \", txt)\n  txt <- gsub(\"'d \", \" would \", txt)\n  txt <- gsub(\"n't \", \" not \", txt)\n  \n  txt <- gsub(\" r \", \" are \", txt)\n  txt <- gsub(\" u \", \" you \", txt)\n  txt <- gsub(\" n \", \" and \", txt)\n  \n  txt <- gsub(\" wld \", \" would \", txt)\n  txt <- gsub(\" cld \", \" could \", txt)\n  txt <- gsub(\" thru \", \" through \", txt)\n  \n  txt <- gsub(\" d; \", \" \", txt)\n  txt <- gsub(\" p; \", \" \", txt)\n  \n  \n  # cleaning the data:\n  # 1. convert to lower case --- expected to be done\n  #txt <- tolower(txt)\n  # 2. remove extra whitespace\n  txt <- stripWhitespace(txt)\n  # 3. remove bad words\n  txt <- removeWords(txt, stopwords('english'))\n  # 4. remove punctuation\n  txt <- removePunctuation(txt)\n  # 5. remove numbers\n  txt <- removeNumbers(txt)\n  \n  # stem documents\n  txt <- stemDocument(txt)\n  \n  return( txt )\n}\n\ngetTopNGram <- function( ngram.df , term, n_top ) {\n  res.df   <- ngram.df[which(term==ngram.df$pre),]\n  topTerms <- res.df[order(res.df$count, decreasing=TRUE), c('pred', 'count')]\n  \n  n <- nrow(topTerms)\n  n <- ifelse(n_top > n, n, n_top)\n  \n  topTerms$pred  <- as.character(topTerms$pred)\n  topTerms$count <- as.integer(topTerms$count)\n  \n  return( topTerms[1:n,] )\n}\n\n\npredictWordNgram <- function( sentence ) {\n  en_txt <- ''\n  top.ngram <- data.frame(pred=character(0), count= integer(0))\n  \n  en_txt <- cleanEnText(sentence)\n    \n  words <- unlist(strsplit(en_txt, split=\" \"))\n  len   <- length(words)\n  \n  top.bigram <- getTopNGram(biterm.pred, words[len], 20)\n  top.bigram$count <- top.bigram$count * 2\n  top.ngram  <- rbind(top.ngram, top.bigram)\n  \n  total.count <- nrow(top.ngram[complete.cases(top.ngram),])\n  if( total.count > 0 ) {\n    if( len > 1 ) {\n      top.trigram <- getTopNGram(triterm.pred, paste(words[len-1],words[len]), 20)\n      top.trigram$count <- top.trigram$count * 3\n      top.ngram <- rbind(top.ngram, top.trigram)\n    \n      if( len > 2 ) {\n        top.quadigram <- getTopNGram(quaditerm.pred, paste(words[len-2],paste(words[len-1],words[len])), 20)\n        top.quadigram$count <- top.quadigram$count * 9\n        top.ngram <- rbind(top.ngram, top.quadigram)\n      }\n    \n      top.ngram <- aggregate(count ~ pred, data=top.ngram, FUN=sum)\n    }\n  \n    top.ngram <- top.ngram[order(top.ngram$count, decreasing=TRUE), ]\n  }\n\n  return( top.ngram )\n}\n\n\n\n\npredictWord <- function( txt ) {\n  s <- '<h4>...</h4>'\n  \n  if(' ' == substr(txt, nchar(txt), nchar(txt))) {\n    \n    word.predict <- predictWordNgram(txt)\n    \n    if( nrow(word.predict[complete.cases(word.predict),]) > 0 ) {\n      s <- sprintf(\"<h3><strong>[1] %s</strong> , [2] %s , [3] %s</h3>\",    \n                  word.predict[1,]$pred,word.predict[2,]$pred,word.predict[3,]$pred)\n    }\n  }\n  else if( nchar(txt) > 0 ) {\n    words <- unlist(strsplit(txt, split=\" \"))\n    len   <- length(words)\n    \n    #check Unigram and Dictionary\n    word.predict <- master_df_unigram[grep(sprintf(\"^%s\", words[len]), master_df_unigram$term),]\n    \n    if( nrow(word.predict[complete.cases(word.predict),]) > 0 ) {\n      word.predict <- word.predict[order(word.predict$count, decreasing=TRUE), ]\n      \n      s <- sprintf(\"<h3><strong>[1] %s</strong> , [2] %s , [3] %s</h3>\",    \n                   word.predict[1,]$term,word.predict[2,]$term,word.predict[3,]$term)\n    }\n    else {\n      #check dictionary\n    }\n  }\n  \n  as.character(s)\n}",
    "created" : 1429856308225.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2773173736",
    "id" : "30B3179B",
    "lastKnownWriteTime" : 1429864457,
    "path" : "D:/EDU/coursera/capstone/wordpredict/global.R",
    "project_path" : "global.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}